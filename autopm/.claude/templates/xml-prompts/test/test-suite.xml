<!--
Template: Comprehensive Test Suite Generation
Purpose: Generate thorough test suite with high coverage
Category: test
Stage: 3
-->

<prompt_workflow>
  <stage>3</stage>
  <workflow_type>test_suite_generation</workflow_type>

  <task>{{task}}</task>

  <context>{{context}}</context>

  <requirements>
    {{#each requirements}}
    <requirement>{{this}}</requirement>
    {{/each}}
  </requirements>

  <constraints>
    <allowed_libraries>{{allowed_libraries}}</allowed_libraries>
    <forbidden_approaches>{{forbidden_approaches}}</forbidden_approaches>
    <test_coverage_minimum>{{test_coverage_minimum}}</test_coverage_minimum>
    <integration_requirements>{{integration_requirements}}</integration_requirements>
  </constraints>

  <test_requirements>
    <framework>Use project's existing test framework (detected via /testing:prime)</framework>
    <no_mocks>CRITICAL - Use real implementations, NO mocks</no_mocks>
    <verbose_output>Tests should have clear descriptions and assertions</verbose_output>
    <isolation>Each test must be independent</isolation>
    <naming>Test names must follow: test_<function>_<scenario>_expectedResult</naming>
  </test_requirements>

  <test_categories>
    <category>
      <name>Happy Path Tests</name>
      <description>Normal operation with valid inputs</description>
      <priority>HIGH</priority>
    </category>
    <category>
      <name>Edge Case Tests</name>
      <description>Boundary conditions and limits</description>
      <priority>HIGH</priority>
    </category>
    <category>
      <name>Error Case Tests</name>
      <description>Invalid inputs and error conditions</description>
      <priority>HIGH</priority>
    </category>
    <category>
      <name>Integration Tests</name>
      <description>Component interaction tests</description>
      <priority>MEDIUM</priority>
    </category>
  </test_categories>

  <deliverables>
    <deliverable>
      <name>Unit Tests</name>
      <description>Tests for individual functions/methods</description>
      <format>Test file with comprehensive test cases</format>
      <required>YES</required>
    </deliverable>
    <deliverable>
      <name>Test Fixtures</name>
      <description>Reusable test data and setup</description>
      <format>Fixture files or setup functions</format>
      <required>Conditional</required>
    </deliverable>
    <deliverable>
      <name>Test Documentation</name>
      <description>Comments explaining complex test scenarios</description>
      <format>Inline comments in test files</format>
      <required>NO</required>
    </deliverable>
  </deliverables>

  <thinking>
    Before creating test suite:

    1. ANALYZE THE CODE:
       - What are the public interfaces?
       - What are the success scenarios?
       - What are the error scenarios?
       - What are the edge cases?

    2. IDENTIFY TEST CATEGORIES:
       - Happy path: Normal usage with valid data
       - Edge cases: Empty inputs, null values, boundary values
       - Errors: Invalid inputs, missing data, conflicts
       - Integration: Multiple components interacting

    3. DESIGN TEST STRUCTURE:
       - How to organize tests logically?
       - What test fixtures are needed?
       - How to handle test setup/teardown?
       - How to manage test data?

    4. PLAN ASSERTIONS:
       - What exactly should be verified?
       - How to assert on results?
       - How to assert on side effects?
       - How to assert on errors?

    5. ENSURE COVERAGE:
       - What code paths need testing?
       - Are all branches covered?
       - Are all error conditions covered?
       - What is the coverage target?

    CRITICAL TESTING PRINCIPLES:
    - Tests must be independent (no shared state)
    - Tests must be repeatable (same result every time)
    - Tests must be verbose (clear failure messages)
    - Tests must test real usage patterns
    - Use REAL implementations, NOT mocks
    - Test name format: test_<function>_<scenario>_<expected>
  </thinking>

  {{#if existing_code}}
  <existing_code>
    <description>Code to be tested</description>
    <content>{{existing_code}}</content>
  </existing_code>
  {{/if}}

  {{#if example}}
  <example>
    <description>Example test patterns from project</description>
    <content>{{example}}</content>
  </example>
  {{/if}}

  <test_naming_conventions>
    <pattern>
      <format>test_<function>_<scenario>_<expected></format>
      <examples>
        - test_userLogin_withValidCredentials_returnsToken
        - test_userLogin_withInvalidCredentials_throwsUnauthorized
        - test_userLogin_withNullEmail_throwsValidationError
        - test_createOrder_withValidData_returnsOrderId
        - test_createOrder_withNegativeQuantity_throwsValidationError
      </examples>
    </pattern>
  </test_naming_conventions>

  <quality_checklist>
    <check>Tests cover all happy paths</check>
    <check>Tests cover all edge cases</check>
    <check>Tests cover all error conditions</check>
    <check>Tests are independent (no shared state)</check>
    <check>Tests use real implementations (no mocks)</check>
    <check>Tests have clear, descriptive names</check>
    <check>Tests have helpful failure messages</check>
    <check>Tests clean up after themselves</check>
    <check>Test coverage meets minimum threshold</check>
    <check>Tests run quickly</check>
    <check>Tests follow project conventions</check>
    <check>Tests are readable and maintainable</check>
  </quality_checklist>
</prompt_workflow>
